/*****************************************************/
/*              SiftTest图像定位测试程序            */
/****************************************************/

#include "stdafx.h"
#include <stdio.h>
#include <iostream>
#include "opencv2/core/core.hpp"//因为在属性中已经配置了opencv等目录，所以把其当成了本地目录一样
#include "opencv2/features2d/features2d.hpp"
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/nonfree/nonfree.hpp" 
#include "windows.h"
#include "opencv2/legacy/legacy.hpp"
#include <fstream>

using namespace cv;
using namespace std;

//设置采样块的步长
const int StepSize = 50;






/************************************************************************/
/*		test_at():测试遍历读取Mat矩阵元素                                                                     */
/************************************************************************/
void InitMat(Mat& m,float t)
{
	for(int i=0;i<m.rows;i++)
		for(int j=0;j<m.cols;j++)
			m.at<float>(i,j)=i+j;
}
void test_at()
{
	//Mat矩阵中的初始化，可以利用Mat：：at()来完成
	///*			①数字测试，at遍历方式ok			*/
	Mat M01(1000,1000,CV_32F);
	InitMat(M01,3);

	/*	②图像Mat测试，不行。	*/
	Mat M0 = imread("C:\\Users\\ZY\\Desktop\\0103\\1_S.jpg");	//大图


	/*		③描述子Mat测试，ok */
	Mat img1 = imread("C:\\Users\\ZY\\Desktop\\0103\\1_S.jpg");	//大图

	int minHessian=5000;
	SurfFeatureDetector detector1(minHessian);
	Ptr<DescriptorExtractor> descriptor_extractor = DescriptorExtractor::create("SURF");
	Mat descriptors_M0;
	//特征点检测			
	vector <KeyPoint> m_LeftKey,m_LeftKey1;		//特征点
	detector1.detect(img1,m_LeftKey);
	descriptor_extractor->compute(img1,m_LeftKey,descriptors_M0);

	ofstream outFile1,outFile2;//创建对象
	outFile1.open("C:\\Users\\ZY\\Desktop\\0105\\descriptor1.txt");//打开文本

	//使用at，遍历核心代码
	for (int i=0;i<descriptors_M0.rows;i++)
	{
		outFile1<<descriptors_M0.row(i)<<endl;
		for (int j=0;j<descriptors_M0.cols;j++)
		{
			outFile1<<descriptors_M0.at<float>(i,j)<<endl;		//这里的i和j分别表示行和列，注意不要搞反了
		}
	}
	
}

/************************************************************************/
/*		测试程序：从txt读入一行数据到数组                                                        */
/************************************************************************/
int main2()
{
	int x[5],y[5];
	int i;
	FILE *fp;
	fp=fopen("C:\\Users\\ZY\\Desktop\\0103\\0106.txt","r");
	for (i=0;i<5;i++) fscanf(fp,"%d",&x[i]);
	for (i=0;i<5;i++) fscanf(fp,"%d",&y[i]);
	fclose(fp);
	for (i=0;i<5;i++) cout << x[i] << " ";
	cout <<endl;
	for (i=0;i<5;i++) cout << y[i] << " ";
	cout <<endl;
	return 0;
}

/************************************************************************/
/*		判断txt共有多少行——方法1                                                                     */
/************************************************************************/
int CountLines(const char *filename)
{
	ifstream ReadFile;
	int n=0;
	string tmp;
	ReadFile.open(filename,ios::in);//ios::in 表示以只读的方式读取文件
	if(ReadFile.fail())//文件打开失败:返回0
	{
		return 0;
	}
	else//文件存在
	{
		while(getline(ReadFile,tmp,'\n'))
		{
			n++;
		}
		ReadFile.close();
		return n;
	}
}

/************************************************************************/
/*		判断txt共有多少行——方法2                                                                     */
/************************************************************************/
int CountLines2(const char *filename)
{
	const int N =100;
	char buf[N];
	int count = 0;
	FILE *fp = fopen(filename,"r");
	if (fp == NULL)
	{
		cout<<"open falied"<<endl;
		return -1;// -1;
	}
	while(fgets(buf,N,fp) != NULL)
	{
		if(buf[strlen(buf) - 1] == '\n')
			count++;	//	count表示文件中数据的行数
	}
	return count;
}


/************************************************************************/
/*		main()函数：
		1，实现大图描述子实时处理和先验处理的时间对比
		2，提取描述子写入txt;
		3，从txt读取数据，写入Mat结构
*/
/************************************************************************/
int main()
{
	initModule_nonfree();
	Mat img1B = imread("E:\\test_Match\\BIG_Small\\Small\\Image1\\1_5000.jpg");	//大图
	Mat img2B = imread("E:\\test_Match\\BIG_Small\\Small\\Image1\\2.jpg");	//大图
	//进行降采样操作
	Mat img1,img2;
	pyrDown(img1B, img1, Size(img1B.cols / 2, img1B.rows / 2));				//1/2降采样
	pyrDown(img1, img1, Size(img1.cols / 2, img1.rows / 2));
	pyrDown(img2B, img2, Size(img2B.cols / 2, img2B.rows / 2));				//1/2降采样
	pyrDown(img2, img2, Size(img2.cols / 2, img2.rows / 2));

	int minHessian=1000;
	SurfFeatureDetector detector1(minHessian);
	Ptr<DescriptorExtractor> descriptor_extractor = DescriptorExtractor::create("SURF");
	Ptr<DescriptorMatcher> descriptor_matcher = DescriptorMatcher::create("BruteForce");//创建特征匹配器

	//特征点检测			
	vector <KeyPoint> m_LeftKey;		//特征点
	Mat img_m_LeftKey;				//画出特征点的输出结果图像
	Mat descriptors;

	/*对图像做特征点检测和提取描述子时间*/
	double t_after  =(double)cvGetTickCount(); //统计配准总时间

	detector1.detect(img1,m_LeftKey);
	descriptor_extractor->compute(img1,m_LeftKey,descriptors);

	t_after =(double)(cvGetTickCount()-t_after)/(cvGetTickFrequency()*1000*1000.);

	cout<<"特征点数量："<<descriptors.rows<<endl;
	cout<<m_LeftKey.size()<<endl;
	cout<<"对照组t_after时间："<<t_after<<endl;

	/*将数据导入到txt中*/
	ofstream outfile;
	//设置输出文件的保存目录
	outfile.open("C:\\Users\\ZY\\Desktop\\0103\\Descriptors.txt");


	for (int i=0;i<descriptors.rows;i++)
	{
		outfile<<m_LeftKey[i].pt.x<<"\t";
		outfile<<m_LeftKey[i].pt.y<<"\t";
		outfile<<m_LeftKey[i].size<<"\t";
		outfile<<m_LeftKey[i].angle<<"\t";
		outfile<<m_LeftKey[i].response<<"\t";
		outfile<<m_LeftKey[i].octave<<"\t";

		for (int j=0;j<descriptors.cols;j++)
		{
			outfile<<descriptors.at<float>(i,j)<<"\t";	
		}	
		outfile<<"\n";
	}
	outfile.close();

	
	//读取保存好的描述子，并统计时间
	/*打开文件*/
	double t_before  =(double)cvGetTickCount(); //统计配准总时间
	ifstream infile;	//输入流
	const int N =100;
	char buf[N];
	string path="C:\\Users\\ZY\\Desktop\\0103\\Descriptors.txt";
	const char* r_DataPath = path.c_str();
	int count =CountLines2(r_DataPath);			//统计共有多少行
//	cout<<count<<endl;		
	//按行读取txt中的数据，并保存在数组中，再读入相应数据结构中
	double x[70];		//KeyPoint6个+ 64维描述子
	KeyPoint Kp;
	vector <KeyPoint> m_LeftKey2;
	Mat descriptors2;
	
	FILE *fp2 = fopen(r_DataPath,"r");

	while (count--)
	{
		for (int i=0;i<70;i++) 
		{
			fscanf(fp2,"%lf",&x[i]);
		}
			int k=0;
			Kp.pt.x = x[k];
			Kp.pt.y = x[k+1];
			Kp.size = x[k+2];
			Kp.angle = x[k+3];
			Kp.response = x[k+4];
			Kp.octave = x[k+5];
			m_LeftKey2.push_back(Kp);
		
			float ds[64];
		for (int n=6;n<70;n++)
		{
			ds[n-6] = x[n];
		}
		Mat Descr2=Mat(1,64,CV_32F,ds);	//之前写的这一句赋值不对！！解决：CV_32F对应float类型；CV_64F对应double类型
			
			descriptors2.push_back(Descr2);			//descriptors2:从已经保存好的数据中提取的描述子
	}
		t_before =(double)(cvGetTickCount()-t_before)/(cvGetTickFrequency()*1000*1000.);

		cout<<"实验组t_before时间："<<t_before<<endl;

	cout<<m_LeftKey.size()<<","<<m_LeftKey2.size()<<endl;


		cout<<m_LeftKey2.size()<<endl;

		ofstream outFile2("C:\\Users\\ZY\\Desktop\\0103\\Descriptors2.txt");

		for (int i=0;i< descriptors2.rows;i++)
		{

			outFile2<<descriptors2.row(i);
			outFile2<<"\n";
		}

		cout<<descriptors2.rows<<endl;


	
		//对小图操作	
		vector <KeyPoint> m_RightKey;		//特征点
		Mat img_m_RightKey;				//画出特征点的输出结果图像
		Mat descriptorsRight;
		detector1.detect(img2,m_RightKey);
		descriptor_extractor->compute(img2,m_RightKey,descriptorsRight);
		
		vector<DMatch> matches1,matches2;//匹配结果，DMatch是一个结构体
		descriptor_matcher->match(descriptorsRight,descriptors,matches1);//匹配两个图像的特征矩阵
		descriptor_matcher->match(descriptorsRight,descriptors2,matches2);//匹配两个图像的特征矩阵

		////绘制匹配线段
		Mat img_matches1,img_matches2;
		drawMatches(img2,m_RightKey,img1,m_LeftKey,matches1,img_matches1);//大图实时处理，img_matches1
		drawMatches(img2,m_RightKey,img1,m_LeftKey2,matches2,img_matches2);//大图先验处理，img_matches2
		//显示匹配线段
		//显示匹配线段
		imshow("surf_Matches1",img_matches1);//显示的标题为Matches
		imshow("surf_Matches2",img_matches2);//显示的标题为Matches
		
		
		//以下为精匹配过程
		
			double max_dist = 0;
		double min_dist = 100;
		for(int i=0;i<matches2.size();i++)
		{
			double dist = matches2[i].distance;
			if(dist < min_dist) 
				min_dist = dist;
			if(dist > max_dist)
				max_dist = dist;
		}
	
		//设置阈值，筛选较好的匹配点  
		vector<DMatch> goodMatches;
		for(int i=0;i<matches2.size();i++)
		{
			if(matches2[i].distance < 0.5*max_dist)	//这里的阈值设置也是比较重要的
		//	if( matches[i].distance <= max(2*min_dist, 0.02) )
			{
				goodMatches.push_back(matches2[i]);
			}
		}
	
		cout<<"goodMatches个数："<<goodMatches.size()<<endl;
	
	
	
	
		//画出匹配结果
		Mat img_matches;
		//使用红色连接匹配的特征点对，绿色未匹配点对
	
		drawMatches(img2,m_RightKey,img1,m_LeftKey2,goodMatches,img_matches,
				Scalar::all(-1),CV_RGB(0,255,0),Mat(),2);//最后一位是标志位，显示画圈的大小等
		imshow("Match_surf",img_matches);
	
		double t_RANSAC =(double)cvGetTickCount();
	
		//RANSAC匹配过程
		vector<DMatch> m_Matches = goodMatches;
		//分配空间
		int ptCount = m_Matches.size();//int ptCount = (int)m_Matches.size()不用这句里的强制转换试试
		Mat p1(ptCount,2,CV_32F);//创建一个Mat结构，点数行，2列，32位浮点型
		Mat p2(ptCount,2,CV_32F);
	
		//把得到的Keypoint转换为Mat
		Point2f pt;
		for(int i=0;i<m_Matches.size();i++)
		{
			pt = m_RightKey[m_Matches[i].queryIdx].pt;
			p1.at<float>(i,0) = pt.x;//第一列表示x坐标；第二列表示y；//迭代器，at函数用来读取矩阵中的某个像素
			p1.at<float>(i,1) = pt.y;
			
			
			pt = m_LeftKey2[m_Matches[i].trainIdx].pt;
			p2.at<float>(i,0) = pt.x;
			p2.at<float>(i,1) = pt.y;
		}
	
		//用RANSAC方法计算F
		Mat m_Fundamental;//计算基本矩阵
		vector<uchar> m_RANSACStatus;//该变量用来存储RANSAC之后，每个点的状态
		findFundamentalMat(p1,p2,m_RANSACStatus,FM_RANSAC);//最后一位是标志位，表示使用RANSAC算法
	
		//计算野点个数
		int OutlinerCount = 0;
		for(int i=0;i<m_Matches.size();i++)
		{
			if(m_RANSACStatus[i] == 0)			//状态为0表示是野点
			{
				OutlinerCount++;
			}
		}
		int InlinerCount = ptCount - OutlinerCount;
		cout<<"内点个数为："<<InlinerCount<<endl;
	
		//创建3个变量用来保存内点和匹配关系
		vector<Point2f> m_LeftInlier;
		vector<Point2f> m_RightInlier;
		vector<DMatch> m_InlierMatches;
	
		
		m_LeftInlier.resize(InlinerCount  );		//调整容器的长度大小，使其能容纳n 个元素(为了防止有内存溢出问题，给每个结构大小多加10)
		m_RightInlier.resize(InlinerCount  );
		m_InlierMatches.resize(InlinerCount  );
	
		InlinerCount = 0;
	//	float inlier_minRx =  img1.cols;	//存储内点中右图最小横坐标，便于后续融合 //可是这里为什么是img1??——相当于，将右图拼接紧挨左图
		float inlier_minRx =  0;
		
		for(int i =0;i<ptCount;i++)
		{
			if(m_RANSACStatus[i] != 0)	//将正确匹配的点赋给内点
			{
				m_LeftInlier[InlinerCount].x = p1.at<float>(i,0);
				m_LeftInlier[InlinerCount].y = p1.at<float>(i,1);
				m_RightInlier[InlinerCount].x = p2.at<float>(i,0);
				m_RightInlier[InlinerCount].y = p2.at<float>(i,1);
				m_InlierMatches[InlinerCount].queryIdx = InlinerCount;
				m_InlierMatches[InlinerCount].trainIdx = InlinerCount;
	
				if(m_RightInlier[InlinerCount].x < inlier_minRx)
					inlier_minRx = m_RightInlier[InlinerCount].x;		//存储内点中右图的最小坐标
				InlinerCount++;
			}
		}
	
		t_RANSAC =(double)(cvGetTickCount()-t_RANSAC)/(cvGetTickFrequency()*1000*1000.);
		//	cout<<"RANSAC方法用时："<<t_RANSAC<<endl;
	
	
		//将内点转换成drawMatches可以用的格式：m_InlierMatches转换成Keypoint
		vector<KeyPoint> key1(InlinerCount);
		vector<KeyPoint> key2(InlinerCount);
		KeyPoint::convert(m_LeftInlier,key1);
		KeyPoint::convert(m_RightInlier,key2);
	
		//显示计算F之后的内点匹配
		Mat OutImage;
		drawMatches(img2,key1,img1,key2,m_InlierMatches,OutImage);
		//cvNamedWindow("match features",1);
		imshow("基础矩阵匹配结果",OutImage);
	

		
	fclose(fp2);
   	waitKey(0);
	system("pause");

	return 0;
}





